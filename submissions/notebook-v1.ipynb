{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c739d4b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-15T21:58:42.903556Z",
     "iopub.status.busy": "2023-10-15T21:58:42.903205Z",
     "iopub.status.idle": "2023-10-15T21:58:44.810249Z",
     "shell.execute_reply": "2023-10-15T21:58:44.808872Z"
    },
    "papermill": {
     "duration": 1.914842,
     "end_time": "2023-10-15T21:58:44.813339",
     "exception": false,
     "start_time": "2023-10-15T21:58:42.898497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.fft import fft\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fa02da9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T21:58:44.822948Z",
     "iopub.status.busy": "2023-10-15T21:58:44.822430Z",
     "iopub.status.idle": "2023-10-15T21:59:01.134253Z",
     "shell.execute_reply": "2023-10-15T21:59:01.132916Z"
    },
    "papermill": {
     "duration": 16.318596,
     "end_time": "2023-10-15T21:59:01.137083",
     "exception": false,
     "start_time": "2023-10-15T21:58:44.818487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Flag to run locally\n",
    "run_local = False\n",
    "\n",
    "if run_local:\n",
    "    df = pd.read_csv('../data/train_logs.csv')\n",
    "    scores = pd.read_csv('../data/train_scores.csv')\n",
    "    df_test = pd.read_csv('../data/test_logs.csv')\n",
    "else:\n",
    "    df = pd.read_csv('/kaggle/input/linking-writing-processes-to-writing-quality/train_logs.csv')\n",
    "    scores = pd.read_csv('/kaggle/input/linking-writing-processes-to-writing-quality/train_scores.csv')\n",
    "    df_test = pd.read_csv('/kaggle/input/linking-writing-processes-to-writing-quality/test_logs.csv')\n",
    "\n",
    "df = df.merge(scores, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bb78ed3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T21:59:01.144045Z",
     "iopub.status.busy": "2023-10-15T21:59:01.143650Z",
     "iopub.status.idle": "2023-10-15T21:59:01.152762Z",
     "shell.execute_reply": "2023-10-15T21:59:01.151748Z"
    },
    "papermill": {
     "duration": 0.014927,
     "end_time": "2023-10-15T21:59:01.154786",
     "exception": false,
     "start_time": "2023-10-15T21:59:01.139859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function for pandas apply that check number of large text changes\n",
    "def count_large_text_changes(text_changes):\n",
    "    return len([tc for tc in text_changes if len(tc) > 20])\n",
    "\n",
    "def count_extremely_large_text_changes(text_changes):\n",
    "    return len([tc for tc in text_changes if len(tc) > 100])\n",
    "\n",
    "# For a given type of activity, count the number of times it occurs\n",
    "def count_nonproduction(action_list):\n",
    "    action_type = 'Nonproduction'\n",
    "    return len([action for action in action_list if action == action_type])\n",
    "\n",
    "# count input\n",
    "def count_input(action_list):\n",
    "    action_type = 'Input'\n",
    "    return len([action for action in action_list if action == action_type])\n",
    "\n",
    "# count remove/cut\n",
    "def count_remove(action_list):\n",
    "    action_type = 'Remove/Cut'\n",
    "    return len([action for action in action_list if action == action_type])\n",
    "\n",
    "# Count Replace\n",
    "def count_replace(action_list):\n",
    "    action_type = 'Replace'\n",
    "    return len([action for action in action_list if action == action_type])\n",
    "\n",
    "# Count Paste\n",
    "def count_paste(action_list):\n",
    "    action_type = 'Paste'\n",
    "    return len([action for action in action_list if action == action_type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cb6fe0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T21:59:01.161799Z",
     "iopub.status.busy": "2023-10-15T21:59:01.161443Z",
     "iopub.status.idle": "2023-10-15T21:59:01.167967Z",
     "shell.execute_reply": "2023-10-15T21:59:01.167018Z"
    },
    "papermill": {
     "duration": 0.012328,
     "end_time": "2023-10-15T21:59:01.169931",
     "exception": false,
     "start_time": "2023-10-15T21:59:01.157603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def raw_aggregation_functions(df):\n",
    "\n",
    "    # Feature engineering for typing behavior features\n",
    "    typing_features = df.groupby('id').agg({\n",
    "        'activity': 'count',                # Total number of activities\n",
    "        'action_time': ['sum', 'mean'],     # Total and average action time\n",
    "        'word_count': 'max',                # Maximum word count\n",
    "        'text_change': 'nunique',           # Number of unique text changes\n",
    "        'cursor_position': 'mean',           # Average cursor position\n",
    "        'text_change' : count_large_text_changes,\n",
    "        'text_change' : count_extremely_large_text_changes,\n",
    "        'activity': count_nonproduction,\n",
    "        'activity': count_input,\n",
    "        'activity': count_remove,\n",
    "        'activity': count_replace,\n",
    "        'activity': count_paste,\n",
    "    })\n",
    "\n",
    "    # Flatten the multi-level column index\n",
    "    typing_features.columns = ['_'.join(col).strip() for col in typing_features.columns.values]\n",
    "\n",
    "    return typing_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7266ca81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T21:59:01.178378Z",
     "iopub.status.busy": "2023-10-15T21:59:01.177958Z",
     "iopub.status.idle": "2023-10-15T21:59:01.270495Z",
     "shell.execute_reply": "2023-10-15T21:59:01.269525Z"
    },
    "papermill": {
     "duration": 0.098794,
     "end_time": "2023-10-15T21:59:01.272520",
     "exception": false,
     "start_time": "2023-10-15T21:59:01.173726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optimize the function to calculate top N frequencies and their magnitudes for each 'id' using groupby and apply\n",
    "def calculate_fft_features(group):\n",
    "\n",
    "    group['pos'] = group['cursor_position']%30\n",
    "    group['line'] = (group['cursor_position']/30).astype(int)\n",
    "\n",
    "    # Perform Fourier Transform on 'pos'\n",
    "    fft_values = fft(group['pos'])[1:]\n",
    "    \n",
    "    # Generate frequencies corresponding to the Fourier Transform values\n",
    "    frequencies = np.fft.fftfreq(len(fft_values), 1)[1:]\n",
    "    \n",
    "    # Take absolute value to get magnitude\n",
    "    fft_magnitude = np.abs(fft_values)\n",
    "    \n",
    "    # Identify indices where the frequencies are positive\n",
    "    positive_indices = np.where(frequencies > 0)[0]\n",
    "    \n",
    "    # Filter out only positive frequencies and skip the zero frequency\n",
    "    frequencies = frequencies[positive_indices]\n",
    "    magnitudes = fft_magnitude[positive_indices]\n",
    "    \n",
    "    # Frequency Domain Features\n",
    "    peak_freq = frequencies[np.argmax(magnitudes)]\n",
    "    if np.sum(magnitudes) == 0:\n",
    "        mean_freq = 0  # or some other appropriate default value\n",
    "    else:\n",
    "        mean_freq = np.average(frequencies, weights=magnitudes)\n",
    "\n",
    "    median_freq = frequencies[len(magnitudes) // 2]\n",
    "    bandwidth = np.ptp(frequencies)\n",
    "    freq_skewness = scipy.stats.skew(magnitudes)\n",
    "    freq_kurtosis = scipy.stats.kurtosis(magnitudes)\n",
    "\n",
    "    # Other Features\n",
    "    total_energy = np.sum(magnitudes ** 2)\n",
    "    \n",
    "    # Spectral Entropy\n",
    "    psd_norm = np.abs(magnitudes) / np.sum(np.abs(magnitudes))\n",
    "    spectral_entropy = -np.sum(psd_norm * np.log2(psd_norm + np.finfo(float).eps))\n",
    "    \n",
    "    # Spectral Flatness\n",
    "    spectral_flatness = np.exp(np.mean(np.log(magnitudes + np.finfo(float).eps))) / np.mean(magnitudes)\n",
    "    \n",
    "    # Spectral Roll-off\n",
    "    spectral_sum = np.cumsum(magnitudes)\n",
    "    spectral_rolloff = frequencies[np.searchsorted(spectral_sum, 0.85 * spectral_sum[-1])]\n",
    "    \n",
    "    # Statistical Features\n",
    "    mean_amplitude = np.mean(magnitudes)\n",
    "    std_amplitude = np.std(magnitudes)\n",
    "    skew_amplitude = scipy.stats.skew(magnitudes)\n",
    "    kurtosis_amplitude = scipy.stats.kurtosis(magnitudes)\n",
    "\n",
    "    features = {\n",
    "        \"Peak Frequency\": peak_freq,\n",
    "        \"Mean Frequency\": mean_freq,\n",
    "        \"Median Frequency\": median_freq,\n",
    "        \"Bandwidth\": bandwidth,\n",
    "        \"Frequency Skewness\": freq_skewness,\n",
    "        \"Frequency Kurtosis\": freq_kurtosis,\n",
    "        \"Total Energy\": total_energy,\n",
    "        \"Spectral Entropy\": spectral_entropy,\n",
    "        \"Spectral Flatness\": spectral_flatness,\n",
    "        \"Spectral Roll-off\": spectral_rolloff,\n",
    "        \"Mean Amplitude\": mean_amplitude,\n",
    "        \"Std Amplitude\": std_amplitude,\n",
    "        \"Skew Amplitude\": skew_amplitude,\n",
    "        \"Kurtosis Amplitude\": kurtosis_amplitude\n",
    "    }\n",
    "    \n",
    "    return pd.Series(features)\n",
    "\n",
    "def apply_fft_feats(df):\n",
    "    return df.groupby('id').apply(calculate_fft_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc3f5cfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T21:59:01.280083Z",
     "iopub.status.busy": "2023-10-15T21:59:01.279610Z",
     "iopub.status.idle": "2023-10-15T21:59:01.288982Z",
     "shell.execute_reply": "2023-10-15T21:59:01.288017Z"
    },
    "papermill": {
     "duration": 0.01547,
     "end_time": "2023-10-15T21:59:01.290939",
     "exception": false,
     "start_time": "2023-10-15T21:59:01.275469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocessing(df, df_test, scale_needed=True):\n",
    "    \"\"\"\n",
    "    Preprocesses the input dataframes for training and testing.\n",
    "    \"\"\"\n",
    "\n",
    "    X_train = pd.DataFrame({'id': df['id'].unique()})\n",
    "    y_train = df.groupby('id')['score'].first().reset_index(drop=True)\n",
    "    X_test = pd.DataFrame({'id': df_test['id'].unique()})\n",
    "\n",
    "    # Feature engineering\n",
    "    agg_train_list = []\n",
    "    agg_test_list = []\n",
    "\n",
    "    # Aggregate and collect features without merging\n",
    "    for func in [raw_aggregation_functions, apply_fft_feats]:\n",
    "        agg_train = func(df)\n",
    "        agg_test = func(df_test)\n",
    "\n",
    "        # Check if the index name is 'id'\n",
    "        if agg_train.index.name != 'id' or agg_test.index.name != 'id':\n",
    "            raise ValueError(\"The index must be 'id' for aggregation functions.\")\n",
    "        \n",
    "        agg_train_list.append(agg_train)\n",
    "        agg_test_list.append(agg_test)\n",
    "\n",
    "    # Concatenate all aggregated features horizontally, aligned by index\n",
    "    agg_train = pd.concat(agg_train_list, axis=1)\n",
    "    agg_test = pd.concat(agg_test_list, axis=1)\n",
    "\n",
    "    # Reset index before merge\n",
    "    agg_train.reset_index(inplace=True)\n",
    "    agg_test.reset_index(inplace=True)\n",
    "\n",
    "    # Perform a single merge operation\n",
    "    X_train = X_train.merge(agg_train, on='id', how='left')\n",
    "    X_test = X_test.merge(agg_test, on='id', how='left')\n",
    "\n",
    "    # Remove 'id' column before scaling\n",
    "    X_train_ids = X_train['id']\n",
    "    X_train = X_train.drop(columns=['id'])\n",
    "    X_test_ids = X_test['id']\n",
    "    X_test = X_test.drop(columns=['id'])\n",
    "\n",
    "    # Standardize features\n",
    "    if scale_needed:\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train, X_train_ids, y_train, X_test, X_test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77c50318",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T21:59:01.298398Z",
     "iopub.status.busy": "2023-10-15T21:59:01.298031Z",
     "iopub.status.idle": "2023-10-15T21:59:01.303733Z",
     "shell.execute_reply": "2023-10-15T21:59:01.302598Z"
    },
    "papermill": {
     "duration": 0.01179,
     "end_time": "2023-10-15T21:59:01.305902",
     "exception": false,
     "start_time": "2023-10-15T21:59:01.294112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Trains a regression model.\n",
    "    \"\"\"\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = Lasso(alpha=0.1)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7861ba09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T21:59:01.313167Z",
     "iopub.status.busy": "2023-10-15T21:59:01.312766Z",
     "iopub.status.idle": "2023-10-15T21:59:01.317785Z",
     "shell.execute_reply": "2023-10-15T21:59:01.316873Z"
    },
    "papermill": {
     "duration": 0.010965,
     "end_time": "2023-10-15T21:59:01.319717",
     "exception": false,
     "start_time": "2023-10-15T21:59:01.308752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "def predict(model, X_test):\n",
    "    \"\"\"\n",
    "    Makes predictions using the trained model.\n",
    "    \"\"\"\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "950b1d35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T21:59:01.327547Z",
     "iopub.status.busy": "2023-10-15T21:59:01.327208Z",
     "iopub.status.idle": "2023-10-15T21:59:01.332501Z",
     "shell.execute_reply": "2023-10-15T21:59:01.331626Z"
    },
    "papermill": {
     "duration": 0.011608,
     "end_time": "2023-10-15T21:59:01.334283",
     "exception": false,
     "start_time": "2023-10-15T21:59:01.322675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def submit(X_test_ids, preds):\n",
    "    try:\n",
    "        # Check if X_test_ids and preds have the same length\n",
    "        if len(X_test_ids) != len(preds):\n",
    "            raise ValueError(\"The lengths of X_test_ids and preds must match.\")\n",
    "        \n",
    "        # Create a submission file\n",
    "        submission = pd.DataFrame({'id': X_test_ids, 'score': preds})\n",
    "        submission.to_csv('./submission.csv', index=False)\n",
    "        print('Submitted')\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88f3a37e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T21:59:01.341802Z",
     "iopub.status.busy": "2023-10-15T21:59:01.341401Z",
     "iopub.status.idle": "2023-10-15T21:59:21.376692Z",
     "shell.execute_reply": "2023-10-15T21:59:21.375028Z"
    },
    "papermill": {
     "duration": 20.041395,
     "end_time": "2023-10-15T21:59:21.378669",
     "exception": true,
     "start_time": "2023-10-15T21:59:01.337274",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train, X_train_ids, y_train, X_test, X_test_ids \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_needed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m train(X_train, y_train)\n\u001b[1;32m      3\u001b[0m preds \u001b[38;5;241m=\u001b[39m predict(model, X_test)\n",
      "Cell \u001b[0;32mIn[6], line 17\u001b[0m, in \u001b[0;36mpreprocessing\u001b[0;34m(df, df_test, scale_needed)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m [raw_aggregation_functions, apply_fft_feats]:\n\u001b[1;32m     16\u001b[0m     agg_train \u001b[38;5;241m=\u001b[39m func(df)\n\u001b[0;32m---> 17\u001b[0m     agg_test \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Check if the index name is 'id'\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m agg_train\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m agg_test\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "Cell \u001b[0;32mIn[5], line 75\u001b[0m, in \u001b[0;36mapply_fft_feats\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_fft_feats\u001b[39m(df):\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcalculate_fft_features\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:1353\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1351\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1352\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1353\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selected_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1354\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1355\u001b[0m         \u001b[38;5;66;03m# gh-20949\u001b[39;00m\n\u001b[1;32m   1356\u001b[0m         \u001b[38;5;66;03m# try again, with .apply acting as a filtering\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[38;5;66;03m# fails on *some* columns, e.g. a numeric operation\u001b[39;00m\n\u001b[1;32m   1361\u001b[0m         \u001b[38;5;66;03m# on a string grouper column\u001b[39;00m\n\u001b[1;32m   1363\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_apply_general(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:1402\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_apply_general\u001b[39m(\n\u001b[1;32m   1369\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1374\u001b[0m     is_agg: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1375\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;124;03m    Apply function f in python space\u001b[39;00m\n\u001b[1;32m   1378\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;124;03m        data after applying f\u001b[39;00m\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1402\u001b[0m     values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1404\u001b[0m         not_indexed_same \u001b[38;5;241m=\u001b[39m mutated\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/groupby/ops.py:767\u001b[0m, in \u001b[0;36mBaseGrouper.apply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[1;32m    766\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[0;32m--> 767\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[1;32m    769\u001b[0m     mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 24\u001b[0m, in \u001b[0;36mcalculate_fft_features\u001b[0;34m(group)\u001b[0m\n\u001b[1;32m     21\u001b[0m magnitudes \u001b[38;5;241m=\u001b[39m fft_magnitude[positive_indices]\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Frequency Domain Features\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m peak_freq \u001b[38;5;241m=\u001b[39m frequencies[\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmagnitudes\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(magnitudes) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     26\u001b[0m     mean_freq \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# or some other appropriate default value\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:1216\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m-> 1216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "X_train, X_train_ids, y_train, X_test, X_test_ids = preprocessing(df, df_test, scale_needed=True)\n",
    "model = train(X_train, y_train)\n",
    "preds = predict(model, X_test)\n",
    "submit(X_test_ids, preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 42.59591,
   "end_time": "2023-10-15T21:59:22.203766",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-15T21:58:39.607856",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
