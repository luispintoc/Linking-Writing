{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import scipy\n","from scipy.fft import fft\n","import re\n","import random, os\n","\n","from sklearn.linear_model import Lasso\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.ensemble import RandomForestRegressor"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def seed_everything(seed=1234):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","SEED = 1234\n","seed_everything(SEED)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Flag to run locally\n","run_local = True\n","\n","if run_local:\n","    df = pd.read_csv('../data/train_logs.csv')\n","    scores = pd.read_csv('../data/train_scores.csv')\n","    df_test = df\n","else:\n","    df = pd.read_csv('/kaggle/input/linking-writing-processes-to-writing-quality/train_logs.csv')\n","    scores = pd.read_csv('/kaggle/input/linking-writing-processes-to-writing-quality/train_scores.csv')\n","    df_test = pd.read_csv('/kaggle/input/linking-writing-processes-to-writing-quality/test_logs.csv')\n","\n","df = df.merge(scores, on='id')"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# ------------- Check the size of a text change, \n","# Note: Should be applied to column \"text_change\"\n","\n","# Function for pandas apply that check number of large text changes\n","def count_large_text_changes(text_changes, size=20):\n","    return len([tc for tc in text_changes if len(tc) > size])\n","\n","def count_extremely_large_text_changes(text_changes, size=100):\n","    return len([tc for tc in text_changes if len(tc) > size])\n","\n","def count_tiny_text_changes(text_changes, size=5):\n","    return len([tc for tc in text_changes if len(tc) < size])\n","\n","# ------------- For a given type of activity, count the number of times it occurs ------------ #\n","# Note: Should be applied to column \"activity\"\n","\n","# Count nonproduction\n","def count_nonproduction(action_list):\n","    return len([action for action in action_list if action == 'Nonproduction'])\n","\n","# count input\n","def count_input(action_list):\n","    return len([action for action in action_list if action == 'Input'])\n","\n","# count remove/cut\n","def count_remove(action_list):\n","    return len([action for action in action_list if action == 'Remove/Cut'])\n","\n","# Count Replace\n","def count_replace(action_list):\n","    return len([action for action in action_list if action == 'Replace'])\n","\n","# Count Paste\n","def count_paste(action_list):\n","    return len([action for action in action_list if action == 'Paste'])\n","\n","# ------------- For a given chunk of text that was moved, determine the size and the distance moved ------------ #\n","# Create move vectors features uses the four helpers below\n","def create_move_vectors_features(df): \n","    \n","    # Create selection_vectors (the position of the selection before and after the move)\n","    df['selection_vectors'] = df['activity'].map(get_move_from_vectors)\n","\n","    # Create functions from this\n","    df['distance_of_moved_selection'] = df['selection_vectors'].map(distance_of_move_of_selection)\n","    df['size_of_moved_selection'] = df['selection_vectors'].map(size_of_moved_selection)\n","    df.drop(['selection_vectors'], axis=1, inplace=True)\n","\n","    return df\n","\n","# Function to extract the distance vectors from the activity column\n","def split_activity(activity):\n","    return [np.array(a[1:-1].split(', '), dtype=int) for a in re.findall(r'\\[[0-9]*, [0-9]*\\]', activity)]\n","\n","# Extract the vectors from the activity column when Move From is in the activity\n","def get_move_from_vectors(activity):\n","    if 'Move From' in activity:\n","        return split_activity(activity)\n","    else:\n","        return []\n","    \n","def distance_of_move_of_selection(selection_vectors):\n","    if len(selection_vectors) > 0:\n","        return selection_vectors[1][0] - selection_vectors[0][0]\n","    else:\n","        return 0\n","\n","# How large was the selection\n","def size_of_moved_selection(selection_vectors):\n","    if len(selection_vectors) > 0:\n","        return selection_vectors[0][1] - selection_vectors[0][0]\n","    else:\n","        return 0\n","\n","## Time features\n","### The total amount of time spent on the essay (as a fraction of total time allowed)\n","# The total amount of time the person spent writing the essay as a fraction of the total time\n","def fraction_of_time_spent_writing(writing_times):\n","    total_time = 1800000 # Half an hour in milliseconds\n","    max_time = max(writing_times)\n","    return max_time / total_time\n","\n","# This function simply normalizes the text of Move From to be uniform, \n","# should be used once Move From features have already been created\n","def normalize_move_from(activity):\n","    if 'Move From' in activity:\n","        return 'Move From'\n","    else:\n","        return activity\n","    \n","def create_action_time_features(df):\n","    # Normalize move from column\n","    df['activity'] = df['activity'].map(normalize_move_from)\n","\n","    # Calculate average time, max time and total time of different actions\n","    action_time_features = df.groupby(['id', 'activity']).agg(\n","        {'action_time': ['mean', 'max', 'sum', 'count']}\n","    )\n","\n","    # Flatten multi index columns\n","    action_time_features.columns = ['_'.join(col).strip() for col in action_time_features.columns.values]\n","\n","    # Unstack multi index rows\n","    action_time_features = action_time_features.unstack('activity')\n","\n","    # Re-flatten multi index columns\n","    action_time_features.columns = ['_'.join(col).strip() for col in action_time_features.columns.values]\n","    action_time_features.fillna(0, inplace=True) # Fill na with 0s \n","    return action_time_features\n","\n","def raw_aggregation_functions(df):\n","\n","    # Create features related to individual action time\n","    action_time_features = create_action_time_features(df)\n","\n","    # Create features related to moved selections of text\n","    df = create_move_vectors_features(df)\n","\n","    # Feature engineering for typing behavior features\n","    typing_features = df.groupby('id').agg({\n","        'activity': 'count',                # Total number of activities\n","        'action_time': ['sum', 'mean'],     # Total and average action time\n","        'word_count': 'max',                # Maximum word count\n","        'text_change': 'nunique',           # Number of unique text changes\n","        'cursor_position': 'mean',           # Average cursor position\n","        'text_change' : count_large_text_changes,\n","        'text_change' : count_extremely_large_text_changes,\n","        'text_change' : count_tiny_text_changes,\n","        'activity': count_nonproduction,\n","        'activity': count_input,\n","        'activity': count_remove,\n","        'activity': count_replace,\n","        'activity': count_paste,\n","        'distance_of_moved_selection': ['mean', 'max'],\n","        'size_of_moved_selection': ['mean', 'max'],\n","        'up_time': fraction_of_time_spent_writing, # Amount of time spent on the essay,\n","    })\n","\n","    # Flatten the multi-level column index\n","    typing_features.columns = ['_'.join(col).strip() for col in typing_features.columns.values]\n","\n","    # Merge action time features with typing features\n","    features = pd.merge(typing_features, action_time_features, on='id')\n","    \n","    return features\n","\n","# Optimize the function to calculate top N frequencies and their magnitudes for each 'id' using groupby and apply\n","def calculate_fft_features(group):\n","\n","    group['pos'] = group['cursor_position']%30\n","    group['line'] = (group['cursor_position']/30).astype(int)\n","\n","    # Perform Fourier Transform on 'pos'\n","    fft_values = fft(group['pos'])[1:]\n","    \n","    # Generate frequencies corresponding to the Fourier Transform values\n","    frequencies = np.fft.fftfreq(len(fft_values), 1)[1:]\n","    \n","    # Take absolute value to get magnitude\n","    fft_magnitude = np.abs(fft_values)\n","    \n","    # Identify indices where the frequencies are positive\n","    positive_indices = np.where(frequencies > 0)[0]\n","    \n","    # Filter out only positive frequencies and skip the zero frequency\n","    frequencies = frequencies[positive_indices]\n","    magnitudes = fft_magnitude[positive_indices]\n","    \n","    # Frequency Domain Features\n","    peak_freq = frequencies[np.argmax(magnitudes)]\n","    if np.sum(magnitudes) == 0:\n","        mean_freq = 0  # or some other appropriate default value\n","    else:\n","        mean_freq = np.average(frequencies, weights=magnitudes)\n","\n","    median_freq = frequencies[len(magnitudes) // 2]\n","    bandwidth = np.ptp(frequencies)\n","    freq_skewness = scipy.stats.skew(magnitudes)\n","    freq_kurtosis = scipy.stats.kurtosis(magnitudes)\n","\n","    # Other Features\n","    total_energy = np.sum(magnitudes ** 2)\n","    \n","    # Spectral Entropy\n","    psd_norm = np.abs(magnitudes) / np.sum(np.abs(magnitudes))\n","    spectral_entropy = -np.sum(psd_norm * np.log2(psd_norm + np.finfo(float).eps))\n","    \n","    # Spectral Flatness\n","    spectral_flatness = np.exp(np.mean(np.log(magnitudes + np.finfo(float).eps))) / np.mean(magnitudes)\n","    \n","    # Spectral Roll-off\n","    spectral_sum = np.cumsum(magnitudes)\n","    spectral_rolloff = frequencies[np.searchsorted(spectral_sum, 0.85 * spectral_sum[-1])]\n","    \n","    # Statistical Features\n","    mean_amplitude = np.mean(magnitudes)\n","    std_amplitude = np.std(magnitudes)\n","    skew_amplitude = scipy.stats.skew(magnitudes)\n","    kurtosis_amplitude = scipy.stats.kurtosis(magnitudes)\n","\n","    features = {\n","        \"Peak Frequency\": peak_freq,\n","        \"Mean Frequency\": mean_freq,\n","        \"Median Frequency\": median_freq,\n","        \"Bandwidth\": bandwidth,\n","        \"Frequency Skewness\": freq_skewness,\n","        \"Frequency Kurtosis\": freq_kurtosis,\n","        \"Total Energy\": total_energy,\n","        \"Spectral Entropy\": spectral_entropy,\n","        \"Spectral Flatness\": spectral_flatness,\n","        \"Spectral Roll-off\": spectral_rolloff,\n","        \"Mean Amplitude\": mean_amplitude,\n","        \"Std Amplitude\": std_amplitude,\n","        \"Skew Amplitude\": skew_amplitude,\n","        \"Kurtosis Amplitude\": kurtosis_amplitude\n","    }\n","    \n","    return pd.Series(features)\n","\n","def apply_fft_feats(df):\n","    return df.groupby('id').apply(calculate_fft_features)\n","\n","##### MAKE SURE FUNC LIST IS UPDATED BEFORE RUNNING/PASTING TO NOTEBOOK #####\n","func_list = [raw_aggregation_functions, apply_fft_feats]"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def preprocessing(df, df_test, func_list, scale_needed=True, run_local=True):\n","    \"\"\"\n","    Preprocesses the input dataframes for training and testing.\n","    \"\"\"\n","\n","    X_train = pd.DataFrame({'id': df['id'].unique()})\n","    y_train = df.groupby('id')['score'].first().reset_index(drop=True)\n","    X_test = pd.DataFrame({'id': df_test['id'].unique()})\n","\n","    # Feature engineering\n","    agg_train_list = []\n","    agg_test_list = []\n","\n","    # Aggregate and collect features without merging\n","    for func in func_list:\n","        agg_train = func(df)\n","        agg_test = func(df_test)\n","\n","        # Check if the index name is 'id'\n","        if agg_train.index.name != 'id' or agg_test.index.name != 'id':\n","            raise ValueError(\"The index must be 'id' for aggregation functions.\")\n","        \n","        agg_train_list.append(agg_train)\n","        agg_test_list.append(agg_test)\n","\n","    # Concatenate all aggregated features horizontally, aligned by index\n","    agg_train = pd.concat(agg_train_list, axis=1)\n","    agg_test = pd.concat(agg_test_list, axis=1)\n","\n","    # Reset index before merge\n","    agg_train.reset_index(inplace=True)\n","    agg_test.reset_index(inplace=True)\n","\n","    # Perform a single merge operation\n","    X_train = X_train.merge(agg_train, on='id', how='left')\n","    X_test = X_test.merge(agg_test, on='id', how='left')\n","\n","    # Remove 'id' column before scaling\n","    X_train_ids = X_train['id']\n","    X_train = X_train.drop(columns=['id'])\n","    X_test_ids = X_test['id']\n","    X_test = X_test.drop(columns=['id'])\n","\n","    # Save X_train before scaling if run_local=True\n","    if run_local:\n","        X_train.to_csv('X_train.csv', index=False)\n","        y_train.to_csv('y_train.csv', index=False)\n","\n","    # Standardize features\n","    if scale_needed:\n","        scaler = StandardScaler()\n","        X_train = scaler.fit_transform(X_train)\n","        X_test = scaler.transform(X_test)\n","    \n","    return X_train, X_train_ids, y_train, X_test, X_test_ids"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def train(X_train, y_train, model_name, feat_list):\n","    \"\"\"\n","    Trains a regression model.\n","    \"\"\"\n","    \n","    if model_name=='shap_model':\n","        model = RandomForestRegressor(n_estimators=25)\n","        model.fit(X_train[feat_list], y_train)\n","\n","    return model"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def get_k_models(X_train, y_train, model_name, feat_lists, seed):\n","    \n","    models = []\n","    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.10, stratify=y_train, random_state=seed)\n","    skf = StratifiedKFold(n_splits=5, random_state=seed, shuffle=True)\n","    \n","    for i, (train_index, val_index) in enumerate(skf.split(X_train, LabelEncoder().fit_transform(y_train))):\n","        x_train_fold, x_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n","        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n","    \n","        model = train(x_train_fold, y_train_fold, model_name, feat_lists[i])\n","    \n","        models.append(model)\n","    \n","    return models"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# Prediction\n","def predict(model, X_test):\n","    \"\"\"\n","    Makes predictions using the trained model.\n","    \"\"\"\n","\n","    preds = model.predict(X_test)\n","    \n","    return preds"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def submit(X_test_ids, preds):\n","    try:\n","        # Check if X_test_ids and preds have the same length\n","        if len(X_test_ids) != len(preds):\n","            raise ValueError(\"The lengths of X_test_ids and preds must match.\")\n","        \n","        # Create a submission file\n","        submission = pd.DataFrame({'id': X_test_ids, 'score': preds})\n","        submission.to_csv('./submission.csv', index=False)\n","        print('Submitted')\n","\n","    except ValueError as e:\n","        print(f\"Error: {e}\")"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Submitted\n"]}],"source":["X_train, X_train_ids, y_train, X_test, X_test_ids = preprocessing(df, df_test, func_list, scale_needed=False, run_local=run_local)\n","\n","'''\n","Shap value feat sel\n","'''\n","shap_feat_lists = [\n","    ['word_count_max', 'distance_of_moved_selection_mean', 'distance_of_moved_selection_max', 'size_of_moved_selection_mean', 'size_of_moved_selection_max', 'action_time_mean_Move From', 'action_time_mean_Replace', 'action_time_max_Input', 'action_time_max_Replace', 'action_time_sum_Move From', 'action_time_sum_Nonproduction', 'action_time_count_Input', 'action_time_count_Move From', 'action_time_count_Nonproduction', 'action_time_count_Remove/Cut'],\n","    ['activity_count_paste', 'action_time_sum', 'action_time_mean', 'word_count_max', 'text_change_count_tiny_text_changes', 'distance_of_moved_selection_mean', 'distance_of_moved_selection_max', 'size_of_moved_selection_mean', 'size_of_moved_selection_max', 'action_time_mean_Input', 'action_time_mean_Move From', 'action_time_mean_Nonproduction', 'action_time_mean_Paste', 'action_time_mean_Remove/Cut', 'action_time_mean_Replace', 'action_time_max_Input', 'action_time_max_Move From', 'action_time_max_Nonproduction', 'action_time_max_Paste', 'action_time_max_Replace', 'action_time_sum_Input', 'action_time_sum_Move From', 'action_time_sum_Nonproduction', 'action_time_sum_Paste', 'action_time_sum_Remove/Cut', 'action_time_sum_Replace', 'action_time_count_Input', 'action_time_count_Move From', 'action_time_count_Nonproduction', 'action_time_count_Paste', 'action_time_count_Replace', 'Mean Frequency', 'Median Frequency', 'Frequency Skewness', 'Frequency Kurtosis', 'Spectral Roll-off', 'Skew Amplitude', 'Kurtosis Amplitude'],\n","    ['activity_count_paste', 'action_time_mean', 'word_count_max', 'text_change_count_tiny_text_changes', 'distance_of_moved_selection_mean', 'distance_of_moved_selection_max', 'size_of_moved_selection_mean', 'size_of_moved_selection_max', 'up_time_fraction_of_time_spent_writing', 'action_time_mean_Input', 'action_time_mean_Move From', 'action_time_mean_Paste', 'action_time_mean_Replace', 'action_time_max_Input', 'action_time_max_Move From', 'action_time_max_Paste', 'action_time_max_Replace', 'action_time_sum_Move From', 'action_time_sum_Paste', 'action_time_sum_Replace', 'action_time_count_Input', 'action_time_count_Move From', 'action_time_count_Nonproduction', 'action_time_count_Paste', 'action_time_count_Replace', 'Peak Frequency', 'Median Frequency', 'Bandwidth'],\n","    ['activity_count_paste', 'action_time_sum', 'word_count_max', 'text_change_count_tiny_text_changes', 'cursor_position_mean', 'distance_of_moved_selection_mean', 'distance_of_moved_selection_max', 'size_of_moved_selection_mean', 'size_of_moved_selection_max', 'up_time_fraction_of_time_spent_writing', 'action_time_mean_Move From', 'action_time_mean_Nonproduction', 'action_time_mean_Paste', 'action_time_mean_Remove/Cut', 'action_time_mean_Replace', 'action_time_max_Input', 'action_time_max_Move From', 'action_time_max_Nonproduction', 'action_time_max_Paste', 'action_time_max_Remove/Cut', 'action_time_max_Replace', 'action_time_sum_Input', 'action_time_sum_Move From', 'action_time_sum_Nonproduction', 'action_time_sum_Paste', 'action_time_sum_Remove/Cut', 'action_time_sum_Replace', 'action_time_count_Input', 'action_time_count_Move From', 'action_time_count_Paste', 'action_time_count_Remove/Cut', 'action_time_count_Replace', 'Peak Frequency', 'Mean Frequency', 'Bandwidth', 'Frequency Skewness', 'Frequency Kurtosis', 'Spectral Roll-off', 'Std Amplitude', 'Skew Amplitude', 'Kurtosis Amplitude'],\n","    ['activity_count_paste', 'action_time_mean', 'word_count_max', 'text_change_count_tiny_text_changes', 'cursor_position_mean', 'distance_of_moved_selection_mean', 'distance_of_moved_selection_max', 'size_of_moved_selection_mean', 'size_of_moved_selection_max', 'up_time_fraction_of_time_spent_writing', 'action_time_mean_Input', 'action_time_mean_Move From', 'action_time_mean_Paste', 'action_time_mean_Remove/Cut', 'action_time_mean_Replace', 'action_time_max_Input', 'action_time_max_Move From', 'action_time_max_Nonproduction', 'action_time_max_Paste', 'action_time_max_Remove/Cut', 'action_time_max_Replace', 'action_time_sum_Input', 'action_time_sum_Move From', 'action_time_sum_Nonproduction', 'action_time_sum_Paste', 'action_time_sum_Remove/Cut', 'action_time_sum_Replace', 'action_time_count_Input', 'action_time_count_Move From', 'action_time_count_Nonproduction', 'action_time_count_Paste', 'action_time_count_Remove/Cut', 'action_time_count_Replace', 'Peak Frequency', 'Mean Frequency', 'Median Frequency', 'Bandwidth', 'Frequency Skewness', 'Frequency Kurtosis', 'Total Energy', 'Spectral Entropy', 'Spectral Flatness', 'Spectral Roll-off', 'Mean Amplitude', 'Std Amplitude', 'Skew Amplitude', 'Kurtosis Amplitude']\n","]\n","\n","models = get_k_models(X_train, y_train, model_name='shap_model', feat_lists=shap_feat_lists, seed=SEED)\n","\n","preds = []\n","for (model, shap_feat_list) in zip(models, shap_feat_lists):\n","    preds.append(predict(model, X_test[shap_feat_list]))\n","\n","# Take mean over K-folds\n","preds = np.mean(preds, axis=0)\n","\n","\n","'''\n","Submit\n","'''\n","\n","submit(X_test_ids, preds)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":4}
