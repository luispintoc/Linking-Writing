{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import itertools\n",
    "import pickle\n",
    "import re\n",
    "import time\n",
    "from random import choice, choices\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "from itertools import cycle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "from itertools import cycle\n",
    "from scipy import stats\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn import metrics, model_selection, preprocessing, linear_model, ensemble, decomposition, tree\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepro: change names to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats = pd.read_csv('../../feature_eng/output/train_double_corr_786feats.csv')\n",
    "train_score = pd.read_csv('../../data/train_scores.csv')\n",
    "\n",
    "if 'score' not in train_feats.columns:\n",
    "    train_feats = pd.merge(train_feats, train_score, on='id', how='left')\n",
    "\n",
    "train_feats = train_feats[~train_feats['id'].isin(['3e10785d'])]\n",
    "train_feats.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "cols = train_feats.columns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(train_feats['score'])\n",
    "\n",
    "score_transformed = le.transform(train_feats['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178\n"
     ]
    }
   ],
   "source": [
    "# Options:\n",
    "# \"count_bursts\", \"word_sent_parag_agg\", \"pressed_keys\", \"paussed_features\"\n",
    "# \"segments_visit\", \"paragraph_ratios\", \"time_gaps\", \"cursor_word_changes\"\n",
    "# \"punctuation\", \"key_mouse\", \"time_feat\", \"fft\", \"avg_event_per_minute\", \n",
    "# \"avg_char_deletion_per_minute\", \"avg_char_insert_per_minute\"\n",
    "# \"IKI_word\", \"IKI_sentence\", \"IKI_paragraph\", \"latencies\", \"IWD\"\n",
    "# \"idle\"\n",
    "\n",
    "endings_to_keep = [\"count_bursts\", \"word_sent_parag_agg\", \"idle\", \"latencies\", \"avg_char_deletion_per_minute\", \"avg_char_insert_per_minute\"]\n",
    "endings_to_keep += [\"id\"]\n",
    "\n",
    "dir_to_save = \"low_lgb1\"\n",
    "stratification = True\n",
    "n_jobs = 4\n",
    "noise = True\n",
    "data_augmentation = False\n",
    "\n",
    "iterations = 5\n",
    "n_splits = 3\n",
    "\n",
    "\n",
    "try:\n",
    "    os.mkdir(dir_to_save)\n",
    "except:\n",
    "    print('Already exists')\n",
    "    sys.exit()\n",
    "\n",
    "cols_to_keep = [col for col in train_feats.columns if col.endswith(tuple(endings_to_keep)) or col in ['id', 'score']]\n",
    "\n",
    "with open(f'{dir_to_save}/feature_list.pkl', 'wb') as f:\n",
    "    pickle.dump(cols_to_keep, f)\n",
    "\n",
    "train_feats = train_feats[cols_to_keep]\n",
    "print(len(train_feats.columns)-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "new_columns = {}\n",
    "for col in cols:\n",
    "    if col != 'id' and col != 'score':\n",
    "        new_columns[col] = counter\n",
    "        counter += 1\n",
    "\n",
    "train_feats.rename(columns=new_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = ['score']\n",
    "drop_cols = ['id']\n",
    "train_cols = [col for col in train_feats.columns if col not in target_col + drop_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data_augmentation(x, y, pct=0.75, scale=0.05):\n",
    "#     # Determine the number of rows to create\n",
    "#     num_rows = x.shape[0]\n",
    "#     num_new_rows = int(num_rows * pct)\n",
    "\n",
    "#     # Randomly select rows from the original DataFrame\n",
    "#     indices = np.random.choice(x.index, size=num_new_rows)\n",
    "#     new_rows_x = x.loc[indices]\n",
    "\n",
    "#     # Add Gaussian noise to each numerical column\n",
    "#     for col in new_rows_x.select_dtypes(include=[np.number]).columns:\n",
    "#         noise = np.random.normal(loc=0.0, scale=scale, size=num_new_rows)\n",
    "#         new_rows_x[col] += new_rows_x[col] * noise\n",
    "\n",
    "#     # Append the new rows to the original DataFrame\n",
    "#     x = pd.concat([x, new_rows_x], ignore_index=True)\n",
    "\n",
    "#     # Do the same for y\n",
    "#     new_rows_y = y.loc[indices]\n",
    "#     y = pd.concat([y, new_rows_y], ignore_index=True)\n",
    "\n",
    "#     return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective(trial,train_x,train_y,val_x,val_y,RANDOM_STATE=41, data_augmentation=False):\n",
    "\n",
    "#     params = {\n",
    "#         'reg_lambda': trial.suggest_float('reg_lambda', 1e-4, 10.0, log=True),\n",
    "#         'reg_alpha': trial.suggest_float('reg_alpha', 1e-4, 10.0, log=True),\n",
    "#         'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1), #trial.suggest_categorical('colsample_bytree', [0.4,0.7,1.0]),\n",
    "#         'colsample_bynode': trial.suggest_float('colsample_bynode', 0.5, 1), #trial.suggest_categorical('colsample_bynode', [0.4,0.7,1.0]),\n",
    "#         'subsample': trial.suggest_float('subsample', 0.5, 1),# trial.suggest_categorical('subsample', [0.4,0.7,1.0]),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 1e-4, 5e-2, log=True), #trial.suggest_categorical('learning_rate', [0.008,0.01,0.012,0.014,0.016,0.018, 0.02]),\n",
    "#         'max_depth': trial.suggest_categorical('max_depth', [5,7,9,11,13,15,17,20]),\n",
    "#         'min_child_samples': trial.suggest_categorical('min_child_samples', [7,9,11,13,15,17,20]),\n",
    "#         'num_leaves': trial.suggest_int('num_leaves', 10, 38, step=4),\n",
    "#         'n_estimators': trial.suggest_int('n_estimators', 10, 100, step=10),\n",
    "#     }\n",
    "\n",
    "#     all_params = {\n",
    "#         \"objective\": \"rmse\",\n",
    "#         \"metric\": \"rmse\",\n",
    "#         'random_state': RANDOM_STATE,\n",
    "#         \"verbosity\": -1,\n",
    "#         \"n_jobs\": n_jobs,\n",
    "#         **params\n",
    "#     }\n",
    "\n",
    "#     model = lgb.LGBMRegressor(**all_params)\n",
    "\n",
    "#     if data_augmentation:\n",
    "#         train_x, train_y = data_augmentation(train_x, train_y, pct=0.75, scale=0.05)\n",
    "    \n",
    "#     model.fit(train_x, train_y)\n",
    "    \n",
    "#     preds = model.predict(val_x)\n",
    "    \n",
    "#     rmse = mean_squared_error(val_y, preds, squared=False)\n",
    "    \n",
    "#     return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lgb_calc_OOF(x_train, y_train, x_valid, y_valid, iter, split, RANDOM_STATE=42, noise=False, data_augmentation=False):\n",
    "#     # split into two validations\n",
    "#     x_valid1, x_valid2, y_valid1, y_valid2 = train_test_split(x_valid, y_valid, test_size=0.5, random_state=RANDOM_STATE, shuffle=False)\n",
    "\n",
    "#     '''Use v1, test on v2'''\n",
    "\n",
    "#     # Bayesian Opt using v1\n",
    "#     study = optuna.create_study(direction='minimize')\n",
    "#     study.optimize(lambda trial: objective(trial, x_train, y_train, x_valid1, y_valid1,RANDOM_STATE,data_augmentation), n_trials=20)\n",
    "#     best_trial1 = study.best_trial.params\n",
    "\n",
    "#     # Get best params\n",
    "#     best_params = {\n",
    "#         \"objective\": \"rmse\",\n",
    "#         \"metric\": \"rmse\",\n",
    "#         'random_state': RANDOM_STATE,\n",
    "#         \"verbosity\": -1,\n",
    "#         \"n_jobs\": n_jobs,\n",
    "#         **best_trial1\n",
    "#     }\n",
    "        \n",
    "#     model = lgb.LGBMRegressor(**best_params)\n",
    "#     if data_augmentation:\n",
    "#         x_train, y_train = data_augmentation(x_train, y_train, pct=0.75, scale=0.05)\n",
    "#     if noise:\n",
    "#         y_train = y_train + np.random.normal(0, 0.25, y_train.shape)\n",
    "#     model.fit(x_train, y_train)\n",
    "#     model.booster_.save_model(f'./{dir_to_save}/lgb_iter{iter}_split{split}_val1.txt')\n",
    "\n",
    "#     # Predict on v2\n",
    "#     valid2_predict = model.predict(x_valid2)\n",
    "\n",
    "\n",
    "#     '''Use v2, test on v1'''\n",
    "\n",
    "#     # Bayesian Opt using v2\n",
    "#     study = optuna.create_study(direction='minimize')\n",
    "#     study.optimize(lambda trial: objective(trial, x_train, y_train, x_valid2, y_valid2,RANDOM_STATE,data_augmentation), n_trials=20)\n",
    "#     best_trial2 = study.best_trial.params\n",
    "\n",
    "#     # Get best params\n",
    "#     best_params = {\n",
    "#         \"objective\": \"rmse\",\n",
    "#         \"metric\": \"rmse\",\n",
    "#         'random_state': RANDOM_STATE,\n",
    "#         \"verbosity\": -1,\n",
    "#         \"n_jobs\": n_jobs,\n",
    "#         **best_trial2\n",
    "#     }\n",
    "        \n",
    "#     model = lgb.LGBMRegressor(**best_params)\n",
    "#     if data_augmentation:\n",
    "#         x_train, y_train = data_augmentation(x_train, y_train, pct=0.75, scale=0.05)\n",
    "#     if noise:\n",
    "#         y_train = y_train + np.random.normal(0, 0.25, y_train.shape)\n",
    "#     model.fit(x_train, y_train)\n",
    "#     model.booster_.save_model(f'./{dir_to_save}/lgb_iter{iter}_split{split}_val2.txt')\n",
    "\n",
    "#     # Predict on v1\n",
    "#     valid1_predict = model.predict(x_valid1)\n",
    "\n",
    "#     # Return OOFs\n",
    "#     return np.concatenate([valid1_predict,valid2_predict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_thresh = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high = train_feats[train_feats['score']>score_thresh].copy()\n",
    "df_low = train_feats[train_feats['score']<=score_thresh].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_calc_OOF(x_train, y_train, x_valid, y_valid, x_high, model, early_stop=10, RANDOM_STATE=42, iter=0, split=0):\n",
    "    # split into two validations\n",
    "    x_valid1, x_valid2, y_valid1, y_valid2 = model_selection.train_test_split(x_valid, y_valid, test_size=0.5, random_state=RANDOM_STATE, shuffle=False)\n",
    "\n",
    "    early_stopping_callback = lgb.early_stopping(early_stop, first_metric_only=True, verbose=False)\n",
    "\n",
    "     # Use v1, test on v2\n",
    "    model.fit(x_train, y_train, eval_set=[(x_valid1, y_valid1)],\n",
    "                callbacks=[early_stopping_callback])\n",
    "    \n",
    "    model.booster_.save_model(f'./{dir_to_save}/lgb_iter{iter}_split{split}_val2.txt')\n",
    "\n",
    "    valid2_predict = model.predict(x_valid2)\n",
    "    high_predict = model.predict(x_high)\n",
    "\n",
    "     # Use v2, test on v1\n",
    "    model.fit(x_train, y_train, eval_set=[(x_valid2, y_valid2)],\n",
    "                callbacks=[early_stopping_callback])\n",
    "    \n",
    "    model.booster_.save_model(f'./{dir_to_save}/lgb_iter{iter}_split{split}_val1.txt')\n",
    "\n",
    "    valid1_predict = model.predict(x_valid1)\n",
    "    high_predict += model.predict(x_high)\n",
    "\n",
    "    # Return OOFs\n",
    "    valid_pred = np.concatenate([valid1_predict,valid2_predict])\n",
    "    high_predict = high_predict/2\n",
    "    \n",
    "    return valid_pred, high_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "OOF_HIGH_SCORE = np.zeros(len(df_high))\n",
    "OOF_LOW_SCORE = np.zeros(len(df_low))\n",
    "\n",
    "models_dict = {}\n",
    "preds_dict = {}\n",
    "count = 0\n",
    "for _ in df_low['id'].unique():\n",
    "    preds_dict[count] = []\n",
    "    count+=1\n",
    "\n",
    "\n",
    "for i in range(iterations):\n",
    "\n",
    "    kf = model_selection.KFold(n_splits=n_splits, random_state=41 + i, shuffle=True)\n",
    "    j = 0\n",
    "    for fold, (train_idx, valid_idx) in enumerate(kf.split(df_low)):\n",
    "        \n",
    "        X_train, y_train = df_low.iloc[train_idx][train_cols], df_low.iloc[train_idx][target_col]\n",
    "        if noise:\n",
    "            y_train = y_train + np.random.normal(0, 0.25)\n",
    "        X_valid, y_valid = df_low.iloc[valid_idx][train_cols], df_low.iloc[valid_idx][target_col]\n",
    "        best_params = {\n",
    "                \"objective\": \"rmse\",\n",
    "                \"metric\": \"rmse\",\n",
    "                'random_state': 41 + i,\n",
    "                \"n_estimators\" : 1000,\n",
    "                \"verbosity\": -1,\n",
    "                \"n_jobs\": -1,\n",
    "                \"subsample\": 0.8,\n",
    "                'colsample_bytree': 0.8, \n",
    "                'colsample_bynode': 0.8,\n",
    "            }\n",
    "        \n",
    "        model = lgb.LGBMRegressor(**best_params)\n",
    "        \n",
    "        valid_predict, high_pred = lgb_calc_OOF(X_train, y_train, X_valid, y_valid, \n",
    "                                                           df_high[train_cols],\n",
    "                                                           model, early_stop=15, RANDOM_STATE=41 + i,\n",
    "                                                           iter=i, split=j)\n",
    "\n",
    "        for count, idx in enumerate(valid_idx):\n",
    "            OOF_LOW_SCORE[idx] += valid_predict[count] / iterations\n",
    "\n",
    "        OOF_HIGH_SCORE += high_pred / iterations / n_splits\n",
    "        \n",
    "        models_dict[f'{fold}_{i}'] = model\n",
    "        j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF of true score <=2.0 = 0.40855\n"
     ]
    }
   ],
   "source": [
    "print('OOF of true score <={:.1f} = {:.5f}'.format(score_thresh, metrics.mean_squared_error(df_low[target_col], \n",
    "                                                                   OOF_LOW_SCORE,\n",
    "                                                                   squared=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_low['low reg'] = OOF_LOW_SCORE\n",
    "df_low['flag'] = 1\n",
    "\n",
    "df_high = train_feats[train_feats['score']>score_thresh].copy()\n",
    "df_high['low reg'] = OOF_HIGH_SCORE\n",
    "df_high['flag'] = 0\n",
    "\n",
    "df_all = pd.concat([df_high, df_low], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('OOF before replacement = {:.5f}'.format(metrics.mean_squared_error(df_all[target_col], \n",
    "#                                                                    df_all['pred'],\n",
    "#                                                                    squared=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all.loc[df_all['pred']<=1.5, 'pred'] = df_all['low reg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('OOF after replacement = {:.5f}'.format(metrics.mean_squared_error(df_all[target_col], \n",
    "#                                                                    df_all['pred'], \n",
    "#                                                                    squared=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOF_SCORE = np.zeros(len(train_feats))\n",
    "\n",
    "# models_dict = {}\n",
    "# preds_dict = {}\n",
    "# count = 0\n",
    "# for _ in train_feats['id'].unique():\n",
    "#     preds_dict[count] = []\n",
    "#     count+=1\n",
    "\n",
    "\n",
    "# for i in range(iterations):\n",
    "\n",
    "#     if stratification:\n",
    "#         kf = model_selection.StratifiedKFold(n_splits=n_splits, random_state=41 + i, shuffle=True)\n",
    "#         j = 0\n",
    "#         for fold, (train_idx, valid_idx) in enumerate(kf.split(train_feats, score_transformed)):\n",
    "            \n",
    "#             X_train, y_train = train_feats.iloc[train_idx][train_cols], train_feats.iloc[train_idx][target_col]\n",
    "#             X_valid, y_valid = train_feats.iloc[valid_idx][train_cols], train_feats.iloc[valid_idx][target_col]\n",
    "\n",
    "#             valid_predict = lgb_calc_OOF(X_train, y_train, X_valid, y_valid, i, j, RANDOM_STATE=41 + i, noise=noise, data_augmentation=data_augmentation)\n",
    "\n",
    "#             OOF_SCORE[valid_idx] += valid_predict / iterations\n",
    "#             j+=1\n",
    "\n",
    "#     else:\n",
    "#         kf = model_selection.KFold(n_splits=n_splits, random_state=41 + i, shuffle=True)\n",
    "#         j = 0\n",
    "#         for fold, (train_idx, valid_idx) in enumerate(kf.split(train_feats)):\n",
    "            \n",
    "#             X_train, y_train = train_feats.iloc[train_idx][train_cols], train_feats.iloc[train_idx][target_col]\n",
    "#             X_valid, y_valid = train_feats.iloc[valid_idx][train_cols], train_feats.iloc[valid_idx][target_col]\n",
    "\n",
    "#             valid_predict = lgb_calc_OOF(X_train, y_train, X_valid, y_valid, i, j, RANDOM_STATE=41 + i, noise=noise, data_augmentation=data_augmentation)\n",
    "\n",
    "#             OOF_SCORE[valid_idx] += valid_predict / iterations\n",
    "#             j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('OOF metric LGBM = {:.5f}'.format(metrics.mean_squared_error(train_feats[target_col], \n",
    "#                                                                    OOF_SCORE,\n",
    "#                                                                    squared=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open(f'{dir_to_save}/OOF_base_lgb.pkl', 'wb') as f:\n",
    "#     pickle.dump(OOF_SCORE, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, ax = plt.subplots(figsize=(6, 6))\n",
    "# ax.scatter(OOF_SCORE, train_feats['score'])\n",
    "# add_identity(ax, color='r', ls='--')\n",
    "# # ax.scatter(stds, train_scores_df['score']-means)\n",
    "# plt.ylabel('True Values')\n",
    "# plt.xlabel('Predictions')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
