{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import *\n",
    "from scipy.stats import skew, kurtosis\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_path = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "train_logs = pd.read_csv(f'{input_data_path}/train_logs.csv')\n",
    "train_scores = pd.read_csv(f'{input_data_path}/train_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge logs and scores based on essay ID\n",
    "train_data = pd.merge(train_logs, train_scores, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = ['Input', 'Remove/Cut', 'Nonproduction', 'Replace', 'Paste']\n",
    "events = ['q', 'Space', 'Backspace', 'Shift', 'ArrowRight', 'Leftclick', 'ArrowLeft', '.', ',', \n",
    "              'ArrowDown', 'ArrowUp', 'Enter', 'CapsLock', \"'\", 'Delete', 'Unidentified']\n",
    "text_changes = ['q', ' ', 'NoChange', '.', ',', '\\n', \"'\", '\"', '-', '?', ';', '=', '/', '\\\\', ':']\n",
    "punctuations = ['\"', '.', ',', \"'\", '-', ';', ':', '?', '!', '<', '>', '/',\n",
    "                        '@', '#', '$', '%', '^', '&', '*', '(', ')', '_', '+']\n",
    "gaps = [1, 2, 3, 5, 10, 20, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gap in gaps:\n",
    "    train_data[f'up_time_shift_{gap}'] = train_data.groupby('id')['up_time'].shift(gap)\n",
    "    train_data[f'action_time_gap_{gap}'] = train_data['down_time'] - train_data[f'up_time_shift_{gap}']\n",
    "\n",
    "    train_data[f'cursor_position_shift_{gap}'] = train_data.groupby('id')['cursor_position'].shift(gap)\n",
    "    train_data[f'cursor_position_change_{gap}'] = train_data['cursor_position'] - train_data[f'cursor_position_shift_{gap}']\n",
    "    train_data[f'cursor_position_abs_change_{gap}'] = np.abs(train_data[f'cursor_position_change_{gap}'])\n",
    "\n",
    "    train_data[f'word_count_shift_{gap}'] = train_data.groupby('id')['word_count'].shift(gap)\n",
    "    train_data[f'word_count_change_{gap}'] = train_data['word_count'] - train_data[f'word_count_shift_{gap}']\n",
    "    train_data[f'word_count_abs_change_{gap}'] = np.abs(train_data[f'word_count_change_{gap}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Count nonproduction\n",
    "# def count_nonproduction(action_list):\n",
    "#     return len([action for action in action_list if action == 'Nonproduction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_aggregations = []\n",
    "for gap in gaps:\n",
    "    gap_aggregations.append((f'action_time_gap_{gap}', ['max', 'min', 'mean', 'std', 'sum', skew, kurtosis]))\n",
    "    gap_aggregations.append((f'cursor_position_change_{gap}', ['max', 'min', 'mean', 'std', 'sum', skew, kurtosis]))\n",
    "    gap_aggregations.append((f'cursor_position_abs_change_{gap}', ['max', 'min', 'mean', 'std', 'sum', skew, kurtosis]))\n",
    "    gap_aggregations.append((f'word_count_change_{gap}', ['max', 'min', 'mean', 'std', 'sum', skew, kurtosis]))\n",
    "    gap_aggregations.append((f'word_count_abs_change_{gap}', ['max', 'min', 'mean', 'std', 'sum', skew, kurtosis]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_of_move_of_selection(selection_vectors):\n",
    "    if len(selection_vectors) > 0:\n",
    "        return selection_vectors[1][0] - selection_vectors[0][0]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# How large was the selection\n",
    "def size_of_moved_selection(selection_vectors):\n",
    "    if len(selection_vectors) > 0:\n",
    "        return selection_vectors[0][1] - selection_vectors[0][0]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dict = {\n",
    "    'activity': 'count',                # Total number of activities\n",
    "    'action_time': ['sum', 'mean'],     # Total and average action time\n",
    "    'word_count': 'max',                # Maximum word count\n",
    "    'text_change': 'nunique',           # Number of unique text changes\n",
    "    'cursor_position': 'mean',           # Average cursor position\n",
    "    'text_change' : count_large_text_changes,\n",
    "    'text_change' : count_extremely_large_text_changes,\n",
    "    'text_change' : count_tiny_text_changes,\n",
    "    'activity': count_nonproduction,\n",
    "    'activity': count_input,\n",
    "    'activity': count_remove,\n",
    "    'activity': count_replace,\n",
    "    'activity': count_paste,\n",
    "    'distance_of_moved_selection': ['mean', 'max'],\n",
    "    'size_of_moved_selection': ['mean', 'max'],\n",
    "    'up_time': fraction_of_time_spent_writing, # Amount of time spent on the essay,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dict.update(gap_aggregations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Column(s) ['distance_of_moved_selection', 'size_of_moved_selection'] do not exist\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\luizi\\OneDrive\\Documentos\\GitHub\\Linking-Writing\\feature_eng\\2_feats_from_kagg.ipynb Cell 12\u001b[0m line \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/luizi/OneDrive/Documentos/GitHub/Linking-Writing/feature_eng/2_feats_from_kagg.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Feature engineering for typing behavior features\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/luizi/OneDrive/Documentos/GitHub/Linking-Writing/feature_eng/2_feats_from_kagg.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m typing_features \u001b[39m=\u001b[39m train_data\u001b[39m.\u001b[39;49mgroupby(\u001b[39m'\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49magg(agg_dict)\n",
      "File \u001b[1;32mc:\\Users\\luizi\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:869\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    866\u001b[0m func \u001b[39m=\u001b[39m maybe_mangle_lambdas(func)\n\u001b[0;32m    868\u001b[0m op \u001b[39m=\u001b[39m GroupByApply(\u001b[39mself\u001b[39m, func, args, kwargs)\n\u001b[1;32m--> 869\u001b[0m result \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39;49magg()\n\u001b[0;32m    870\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_dict_like(func) \u001b[39mand\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\luizi\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\apply.py:168\u001b[0m, in \u001b[0;36mApply.agg\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m    167\u001b[0m \u001b[39mif\u001b[39;00m is_dict_like(arg):\n\u001b[1;32m--> 168\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magg_dict_like()\n\u001b[0;32m    169\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(arg):\n\u001b[0;32m    170\u001b[0m     \u001b[39m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[0;32m    171\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magg_list_like()\n",
      "File \u001b[1;32mc:\\Users\\luizi\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\apply.py:467\u001b[0m, in \u001b[0;36mApply.agg_dict_like\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    464\u001b[0m     selected_obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_selected_obj\n\u001b[0;32m    465\u001b[0m     selection \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_selection\n\u001b[1;32m--> 467\u001b[0m arg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnormalize_dictlike_arg(\u001b[39m\"\u001b[39;49m\u001b[39magg\u001b[39;49m\u001b[39m\"\u001b[39;49m, selected_obj, arg)\n\u001b[0;32m    469\u001b[0m \u001b[39mif\u001b[39;00m selected_obj\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    470\u001b[0m     \u001b[39m# key only used for output\u001b[39;00m\n\u001b[0;32m    471\u001b[0m     colg \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_gotitem(selection, ndim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\luizi\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\apply.py:585\u001b[0m, in \u001b[0;36mApply.normalize_dictlike_arg\u001b[1;34m(self, how, obj, func)\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(cols) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    584\u001b[0m         cols_sorted \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(safe_sort(\u001b[39mlist\u001b[39m(cols)))\n\u001b[1;32m--> 585\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mColumn(s) \u001b[39m\u001b[39m{\u001b[39;00mcols_sorted\u001b[39m}\u001b[39;00m\u001b[39m do not exist\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    587\u001b[0m is_aggregator \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: \u001b[39misinstance\u001b[39m(x, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m, \u001b[39mdict\u001b[39m))\n\u001b[0;32m    589\u001b[0m \u001b[39m# if we have a dict of any non-scalars\u001b[39;00m\n\u001b[0;32m    590\u001b[0m \u001b[39m# eg. {'A' : ['mean']}, normalize all to\u001b[39;00m\n\u001b[0;32m    591\u001b[0m \u001b[39m# be list-likes\u001b[39;00m\n\u001b[0;32m    592\u001b[0m \u001b[39m# Cannot use func.values() because arg may be a Series\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Column(s) ['distance_of_moved_selection', 'size_of_moved_selection'] do not exist\""
     ]
    }
   ],
   "source": [
    "# Feature engineering for typing behavior features\n",
    "typing_features = train_data.groupby('id').agg(agg_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activity_counts(df):\n",
    "    tmp_df = df.groupby('id').agg({'activity': list}).reset_index()\n",
    "    ret = list()\n",
    "    for li in tmp_df['activity'].values:\n",
    "        items = list(Counter(li).items())\n",
    "        di = dict()\n",
    "        for k in activities:\n",
    "            di[k] = 0\n",
    "        for item in items:\n",
    "            k, v = item[0], item[1]\n",
    "            if k in di:\n",
    "                di[k] = v\n",
    "        ret.append(di)\n",
    "    ret = pd.DataFrame(ret)\n",
    "    cols = [f'activity_{i}_count' for i in range(len(ret.columns))]\n",
    "    ret.columns = cols\n",
    "    return ret\n",
    "\n",
    "\n",
    "def event_counts(df, colname):\n",
    "    tmp_df = df.groupby('id').agg({colname: list}).reset_index()\n",
    "    ret = list()\n",
    "    for li in tmp_df[colname].values:\n",
    "        items = list(Counter(li).items())\n",
    "        di = dict()\n",
    "        for k in events:\n",
    "            di[k] = 0\n",
    "        for item in items:\n",
    "            k, v = item[0], item[1]\n",
    "            if k in di:\n",
    "                di[k] = v\n",
    "        ret.append(di)\n",
    "    ret = pd.DataFrame(ret)\n",
    "    cols = [f'{colname}_{i}_count' for i in range(len(ret.columns))]\n",
    "    ret.columns = cols\n",
    "    return ret\n",
    "\n",
    "\n",
    "def text_change_counts(df):\n",
    "    tmp_df = df.groupby('id').agg({'text_change': list}).reset_index()\n",
    "    ret = list()\n",
    "    for li in tmp_df['text_change'].values:\n",
    "        items = list(Counter(li).items())\n",
    "        di = dict()\n",
    "        for k in text_changes:\n",
    "            di[k] = 0\n",
    "        for item in items:\n",
    "            k, v = item[0], item[1]\n",
    "            if k in di:\n",
    "                di[k] = v\n",
    "        ret.append(di)\n",
    "    ret = pd.DataFrame(ret)\n",
    "    cols = [f'text_change_{i}_count' for i in range(len(ret.columns))]\n",
    "    ret.columns = cols\n",
    "    return ret\n",
    "\n",
    "def match_punctuations(df):\n",
    "    tmp_df = df.groupby('id').agg({'down_event': list}).reset_index()\n",
    "    ret = list()\n",
    "    for li in tmp_df['down_event'].values:\n",
    "        cnt = 0\n",
    "        items = list(Counter(li).items())\n",
    "        for item in items:\n",
    "            k, v = item[0], item[1]\n",
    "            if k in punctuations:\n",
    "                cnt += v\n",
    "        ret.append(cnt)\n",
    "    ret = pd.DataFrame({'punct_cnt': ret})\n",
    "    return ret\n",
    "\n",
    "\n",
    "def get_input_words(df):\n",
    "    tmp_df = df[(~df['text_change'].str.contains('=>'))&(df['text_change'] != 'NoChange')].reset_index(drop=True)\n",
    "    tmp_df = tmp_df.groupby('id').agg({'text_change': list}).reset_index()\n",
    "    tmp_df['text_change'] = tmp_df['text_change'].apply(lambda x: ''.join(x))\n",
    "    tmp_df['text_change'] = tmp_df['text_change'].apply(lambda x: re.findall(r'q+', x))\n",
    "    tmp_df['input_word_count'] = tmp_df['text_change'].apply(len)\n",
    "    tmp_df['input_word_length_mean'] = tmp_df['text_change'].apply(lambda x: np.mean([len(i) for i in x] if len(x) > 0 else 0))\n",
    "    tmp_df['input_word_length_max'] = tmp_df['text_change'].apply(lambda x: np.max([len(i) for i in x] if len(x) > 0 else 0))\n",
    "    tmp_df['input_word_length_std'] = tmp_df['text_change'].apply(lambda x: np.std([len(i) for i in x] if len(x) > 0 else 0))\n",
    "    tmp_df.drop(['text_change'], axis=1, inplace=True)\n",
    "    return tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineering activity counts data\n",
      "Engineering event counts data\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.00 GiB for an array with shape (16, 8405898) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\luizi\\OneDrive\\Documentos\\GitHub\\Linking-Writing\\feature_eng\\2_feats_from_kagg.ipynb Cell 14\u001b[0m line \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/luizi/OneDrive/Documentos/GitHub/Linking-Writing/feature_eng/2_feats_from_kagg.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEngineering event counts data\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/luizi/OneDrive/Documentos/GitHub/Linking-Writing/feature_eng/2_feats_from_kagg.ipynb#X22sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m tmp_df \u001b[39m=\u001b[39m event_counts(train_data, \u001b[39m'\u001b[39m\u001b[39mdown_event\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/luizi/OneDrive/Documentos/GitHub/Linking-Writing/feature_eng/2_feats_from_kagg.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m feats \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat([feats, tmp_df], axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/luizi/OneDrive/Documentos/GitHub/Linking-Writing/feature_eng/2_feats_from_kagg.ipynb#X22sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m tmp_df \u001b[39m=\u001b[39m event_counts(train_data, \u001b[39m'\u001b[39m\u001b[39mup_event\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/luizi/OneDrive/Documentos/GitHub/Linking-Writing/feature_eng/2_feats_from_kagg.ipynb#X22sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m feats \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([feats, tmp_df], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\luizi\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\luizi\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:359\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[39mConcatenate pandas objects along a particular axis with optional set logic\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[39malong the other axes.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[39mValueError: Indexes have overlapping values: ['a']\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    346\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[0;32m    347\u001b[0m     objs,\n\u001b[0;32m    348\u001b[0m     axis\u001b[39m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    356\u001b[0m     sort\u001b[39m=\u001b[39msort,\n\u001b[0;32m    357\u001b[0m )\n\u001b[1;32m--> 359\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result()\n",
      "File \u001b[1;32mc:\\Users\\luizi\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:592\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    588\u001b[0m             indexers[ax] \u001b[39m=\u001b[39m obj_labels\u001b[39m.\u001b[39mget_indexer(new_labels)\n\u001b[0;32m    590\u001b[0m     mgrs_indexers\u001b[39m.\u001b[39mappend((obj\u001b[39m.\u001b[39m_mgr, indexers))\n\u001b[1;32m--> 592\u001b[0m new_data \u001b[39m=\u001b[39m concatenate_managers(\n\u001b[0;32m    593\u001b[0m     mgrs_indexers, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnew_axes, concat_axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbm_axis, copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy\n\u001b[0;32m    594\u001b[0m )\n\u001b[0;32m    595\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy:\n\u001b[0;32m    596\u001b[0m     new_data\u001b[39m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[1;32mc:\\Users\\luizi\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\concat.py:202\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[39m# Assertions disabled for performance\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# for tup in mgrs_indexers:\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[39m#    # caller is responsible for ensuring this\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m#    indexers = tup[1]\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m#    assert concat_axis not in indexers\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[39mif\u001b[39;00m concat_axis \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 202\u001b[0m     \u001b[39mreturn\u001b[39;00m _concat_managers_axis0(mgrs_indexers, axes, copy)\n\u001b[0;32m    204\u001b[0m mgrs_indexers \u001b[39m=\u001b[39m _maybe_reindex_columns_na_proxy(axes, mgrs_indexers)\n\u001b[0;32m    206\u001b[0m \u001b[39m# Assertion disabled for performance\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[39m# assert all(not x[1] for x in mgrs_indexers)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\luizi\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\concat.py:264\u001b[0m, in \u001b[0;36m_concat_managers_axis0\u001b[1;34m(mgrs_indexers, axes, copy)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[39mconcat_managers specialized to concat_axis=0, with reindexing already\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[39mhaving been done in _maybe_reindex_columns_na_proxy.\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    261\u001b[0m had_reindexers \u001b[39m=\u001b[39m {\n\u001b[0;32m    262\u001b[0m     i: \u001b[39mlen\u001b[39m(mgrs_indexers[i][\u001b[39m1\u001b[39m]) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(mgrs_indexers))\n\u001b[0;32m    263\u001b[0m }\n\u001b[1;32m--> 264\u001b[0m mgrs_indexers \u001b[39m=\u001b[39m _maybe_reindex_columns_na_proxy(axes, mgrs_indexers)\n\u001b[0;32m    266\u001b[0m mgrs \u001b[39m=\u001b[39m [x[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m mgrs_indexers]\n\u001b[0;32m    268\u001b[0m offset \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\luizi\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\concat.py:306\u001b[0m, in \u001b[0;36m_maybe_reindex_columns_na_proxy\u001b[1;34m(axes, mgrs_indexers)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[39mfor\u001b[39;00m mgr, indexers \u001b[39min\u001b[39;00m mgrs_indexers:\n\u001b[0;32m    303\u001b[0m     \u001b[39m# For axis=0 (i.e. columns) we use_na_proxy and only_slice, so this\u001b[39;00m\n\u001b[0;32m    304\u001b[0m     \u001b[39m#  is a cheap reindexing.\u001b[39;00m\n\u001b[0;32m    305\u001b[0m     \u001b[39mfor\u001b[39;00m i, indexer \u001b[39min\u001b[39;00m indexers\u001b[39m.\u001b[39mitems():\n\u001b[1;32m--> 306\u001b[0m         mgr \u001b[39m=\u001b[39m mgr\u001b[39m.\u001b[39;49mreindex_indexer(\n\u001b[0;32m    307\u001b[0m             axes[i],\n\u001b[0;32m    308\u001b[0m             indexers[i],\n\u001b[0;32m    309\u001b[0m             axis\u001b[39m=\u001b[39;49mi,\n\u001b[0;32m    310\u001b[0m             copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    311\u001b[0m             only_slice\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,  \u001b[39m# only relevant for i==0\u001b[39;49;00m\n\u001b[0;32m    312\u001b[0m             allow_dups\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    313\u001b[0m             use_na_proxy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,  \u001b[39m# only relevant for i==0\u001b[39;49;00m\n\u001b[0;32m    314\u001b[0m         )\n\u001b[0;32m    315\u001b[0m     new_mgrs_indexers\u001b[39m.\u001b[39mappend((mgr, {}))\n\u001b[0;32m    317\u001b[0m \u001b[39mreturn\u001b[39;00m new_mgrs_indexers\n",
      "File \u001b[1;32mc:\\Users\\luizi\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\managers.py:692\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    685\u001b[0m     new_blocks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    686\u001b[0m         indexer,\n\u001b[0;32m    687\u001b[0m         fill_value\u001b[39m=\u001b[39mfill_value,\n\u001b[0;32m    688\u001b[0m         only_slice\u001b[39m=\u001b[39monly_slice,\n\u001b[0;32m    689\u001b[0m         use_na_proxy\u001b[39m=\u001b[39muse_na_proxy,\n\u001b[0;32m    690\u001b[0m     )\n\u001b[0;32m    691\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 692\u001b[0m     new_blocks \u001b[39m=\u001b[39m [\n\u001b[0;32m    693\u001b[0m         blk\u001b[39m.\u001b[39mtake_nd(\n\u001b[0;32m    694\u001b[0m             indexer,\n\u001b[0;32m    695\u001b[0m             axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m    696\u001b[0m             fill_value\u001b[39m=\u001b[39m(\n\u001b[0;32m    697\u001b[0m                 fill_value \u001b[39mif\u001b[39;00m fill_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m blk\u001b[39m.\u001b[39mfill_value\n\u001b[0;32m    698\u001b[0m             ),\n\u001b[0;32m    699\u001b[0m         )\n\u001b[0;32m    700\u001b[0m         \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks\n\u001b[0;32m    701\u001b[0m     ]\n\u001b[0;32m    703\u001b[0m new_axes \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n\u001b[0;32m    704\u001b[0m new_axes[axis] \u001b[39m=\u001b[39m new_axis\n",
      "File \u001b[1;32mc:\\Users\\luizi\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\managers.py:693\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    685\u001b[0m     new_blocks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    686\u001b[0m         indexer,\n\u001b[0;32m    687\u001b[0m         fill_value\u001b[39m=\u001b[39mfill_value,\n\u001b[0;32m    688\u001b[0m         only_slice\u001b[39m=\u001b[39monly_slice,\n\u001b[0;32m    689\u001b[0m         use_na_proxy\u001b[39m=\u001b[39muse_na_proxy,\n\u001b[0;32m    690\u001b[0m     )\n\u001b[0;32m    691\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    692\u001b[0m     new_blocks \u001b[39m=\u001b[39m [\n\u001b[1;32m--> 693\u001b[0m         blk\u001b[39m.\u001b[39;49mtake_nd(\n\u001b[0;32m    694\u001b[0m             indexer,\n\u001b[0;32m    695\u001b[0m             axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m    696\u001b[0m             fill_value\u001b[39m=\u001b[39;49m(\n\u001b[0;32m    697\u001b[0m                 fill_value \u001b[39mif\u001b[39;49;00m fill_value \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m blk\u001b[39m.\u001b[39;49mfill_value\n\u001b[0;32m    698\u001b[0m             ),\n\u001b[0;32m    699\u001b[0m         )\n\u001b[0;32m    700\u001b[0m         \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks\n\u001b[0;32m    701\u001b[0m     ]\n\u001b[0;32m    703\u001b[0m new_axes \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n\u001b[0;32m    704\u001b[0m new_axes[axis] \u001b[39m=\u001b[39m new_axis\n",
      "File \u001b[1;32mc:\\Users\\luizi\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:1121\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m   1118\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1119\u001b[0m     allow_fill \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m-> 1121\u001b[0m new_values \u001b[39m=\u001b[39m algos\u001b[39m.\u001b[39;49mtake_nd(\n\u001b[0;32m   1122\u001b[0m     values, indexer, axis\u001b[39m=\u001b[39;49maxis, allow_fill\u001b[39m=\u001b[39;49mallow_fill, fill_value\u001b[39m=\u001b[39;49mfill_value\n\u001b[0;32m   1123\u001b[0m )\n\u001b[0;32m   1125\u001b[0m \u001b[39m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[0;32m   1126\u001b[0m \u001b[39m#  this assertion\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m (axis \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m new_mgr_locs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\luizi\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mtake(indexer, fill_value\u001b[39m=\u001b[39mfill_value, allow_fill\u001b[39m=\u001b[39mallow_fill)\n\u001b[0;32m    116\u001b[0m arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(arr)\n\u001b[1;32m--> 117\u001b[0m \u001b[39mreturn\u001b[39;00m _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)\n",
      "File \u001b[1;32mc:\\Users\\luizi\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\array_algos\\take.py:158\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    156\u001b[0m     out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(out_shape, dtype\u001b[39m=\u001b[39mdtype, order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mF\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    157\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mempty(out_shape, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    160\u001b[0m func \u001b[39m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    161\u001b[0m     arr\u001b[39m.\u001b[39mndim, arr\u001b[39m.\u001b[39mdtype, out\u001b[39m.\u001b[39mdtype, axis\u001b[39m=\u001b[39maxis, mask_info\u001b[39m=\u001b[39mmask_info\n\u001b[0;32m    162\u001b[0m )\n\u001b[0;32m    163\u001b[0m func(arr, indexer, out, fill_value)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.00 GiB for an array with shape (16, 8405898) and data type float64"
     ]
    }
   ],
   "source": [
    "# counts\n",
    "print(\"Engineering activity counts data\")\n",
    "tmp_df = activity_counts(train_data)\n",
    "feats = pd.concat([train_data, tmp_df], axis=1)\n",
    "\n",
    "print(\"Engineering event counts data\")\n",
    "# tmp_df = event_counts(train_data, 'down_event')\n",
    "# feats = pd.concat([feats, tmp_df], axis=1)\n",
    "# tmp_df = event_counts(train_data, 'up_event')\n",
    "# feats = pd.concat([feats, tmp_df], axis=1)\n",
    "\n",
    "print(\"Engineering text change counts data\")\n",
    "tmp_df = text_change_counts(train_data)\n",
    "feats = pd.concat([feats, tmp_df], axis=1)\n",
    "\n",
    "print(\"Engineering punctuation counts data\")\n",
    "tmp_df = match_punctuations(train_data)\n",
    "feats = pd.concat([feats, tmp_df], axis=1)\n",
    "\n",
    "# input words\n",
    "print(\"Engineering input words data\")\n",
    "tmp_df = get_input_words(train_data)\n",
    "feats = pd.merge(feats, tmp_df, on='id', how='left')\n",
    "\n",
    "# compare feats\n",
    "print(\"Engineering ratios data\")\n",
    "feats['word_time_ratio'] = feats['word_count_max'] / feats['up_time_max']\n",
    "feats['word_event_ratio'] = feats['word_count_max'] / feats['event_id_max']\n",
    "feats['event_time_ratio'] = feats['event_id_max']  / feats['up_time_max']\n",
    "feats['idle_time_ratio'] = feats['action_time_gap1_sum'] / feats['up_time_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
