{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import itertools\n",
    "import pickle\n",
    "import re\n",
    "import time\n",
    "from random import choice, choices\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "from itertools import cycle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "from itertools import cycle\n",
    "from scipy import stats\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn import metrics, model_selection, preprocessing, linear_model, ensemble, decomposition, tree\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepro: change names to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feats = pd.read_csv('../../feature_eng/train_419feats.csv')\n",
    "train_score = pd.read_csv('../../data/train_scores.csv')\n",
    "\n",
    "if 'score' not in train_feats.columns:\n",
    "    train_feats = pd.merge(train_feats, train_score, on='id', how='left')\n",
    "\n",
    "train_feats.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "cols = train_feats.columns\n",
    "\n",
    "counter = 0\n",
    "new_columns = {}\n",
    "for col in cols:\n",
    "    if col != 'id' and col != 'score':\n",
    "        new_columns[col] = counter\n",
    "        counter += 1\n",
    "\n",
    "train_feats.rename(columns=new_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = ['score']\n",
    "drop_cols = ['id']\n",
    "train_cols = [col for col in train_feats.columns if col not in target_col + drop_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial,train_x,train_y,val_x,val_y,RANDOM_STATE=41):\n",
    "\n",
    "    params = {\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-4, 10.0, log=True),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-4, 10.0, log=True),\n",
    "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.4,0.7,1.0]),\n",
    "        'colsample_bynode': trial.suggest_categorical('colsample_bynode', [0.4,0.7,1.0]),\n",
    "        'subsample': trial.suggest_categorical('subsample', [0.4,0.7,1.0]),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 5e-2, log=True), #trial.suggest_categorical('learning_rate', [0.008,0.01,0.012,0.014,0.016,0.018, 0.02]),\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [9,11,13,15,17,20]),\n",
    "        'min_child_samples': trial.suggest_categorical('min_child_samples', [7,9,11,13,15,17,20]),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 10, 38, step=4),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1900, step=300),\n",
    "    }\n",
    "\n",
    "    all_params = {\n",
    "        \"objective\": \"rmse\",\n",
    "        \"metric\": \"rmse\",\n",
    "        'random_state': RANDOM_STATE,\n",
    "        \"verbosity\": -1,\n",
    "        \"n_jobs\": -2,\n",
    "        **params\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMRegressor(**all_params)\n",
    "    \n",
    "    model.fit(train_x, train_y)#, eval_set=[(val_x, val_y)], #verbose=False,\n",
    "    \n",
    "    preds = model.predict(val_x)\n",
    "    \n",
    "    rmse = mean_squared_error(val_y, preds, squared=False)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_calc_OOF(x_train, y_train, x_valid, y_valid, iter, split, RANDOM_STATE=42, save=False):\n",
    "    # split into two validations\n",
    "    x_valid1, x_valid2, y_valid1, y_valid2 = train_test_split(x_valid, y_valid, test_size=0.5, random_state=RANDOM_STATE, shuffle=False)\n",
    "\n",
    "    '''Use v1, test on v2'''\n",
    "\n",
    "    # Bayesian Opt using v1\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(lambda trial: objective(trial, x_train, y_train, x_valid1, y_valid1,RANDOM_STATE), n_trials=20)\n",
    "    best_trial1 = study.best_trial.params\n",
    "\n",
    "    # Get best params\n",
    "    best_params = {\n",
    "        \"objective\": \"rmse\",\n",
    "        \"metric\": \"rmse\",\n",
    "        'random_state': RANDOM_STATE,\n",
    "        \"verbosity\": -1,\n",
    "        \"n_jobs\": -2,\n",
    "        **best_trial1\n",
    "    }\n",
    "        \n",
    "    model = lgb.LGBMRegressor(**best_params)\n",
    "    model.fit(x_train, y_train)\n",
    "    if save:\n",
    "        model.booster_.save_model(f'./base_lgb/lgb_iter{iter}_split{split}_val1.txt')\n",
    "\n",
    "    # Predict on v2\n",
    "    valid2_predict = model.predict(x_valid2)\n",
    "\n",
    "\n",
    "    '''Use v2, test on v1'''\n",
    "\n",
    "    # Bayesian Opt using v2\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(lambda trial: objective(trial, x_train, y_train, x_valid2, y_valid2,RANDOM_STATE), n_trials=20)\n",
    "    best_trial2 = study.best_trial.params\n",
    "\n",
    "    # Get best params\n",
    "    best_params = {\n",
    "        \"objective\": \"rmse\",\n",
    "        \"metric\": \"rmse\",\n",
    "        'random_state': RANDOM_STATE,\n",
    "        \"verbosity\": -1,\n",
    "        \"n_jobs\": -2,\n",
    "        **best_trial2\n",
    "    }\n",
    "        \n",
    "    model = lgb.LGBMRegressor(**best_params)\n",
    "    model.fit(x_train, y_train)\n",
    "    if save:\n",
    "        model.booster_.save_model(f'./base_lgb/lgb_iter{iter}_split{split}_val2.txt')\n",
    "\n",
    "    # Predict on v1\n",
    "    valid1_predict = model.predict(x_valid1)\n",
    "\n",
    "    # Return OOFs\n",
    "    return np.concatenate([valid1_predict,valid2_predict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OOF_SCORE = np.zeros(len(train_feats))\n",
    "\n",
    "models_dict = {}\n",
    "preds_dict = {}\n",
    "count = 0\n",
    "for _ in train_feats['id'].unique():\n",
    "    preds_dict[count] = []\n",
    "    count+=1\n",
    "\n",
    "iterations = 5\n",
    "n_splits = 4\n",
    "\n",
    "for i in range(iterations):\n",
    "\n",
    "    kf = model_selection.KFold(n_splits=n_splits, random_state=41 + i, shuffle=True)\n",
    "    j = 0\n",
    "    for fold, (train_idx, valid_idx) in enumerate(kf.split(train_feats)):\n",
    "        \n",
    "        X_train, y_train = train_feats.iloc[train_idx][train_cols], train_feats.iloc[train_idx][target_col]\n",
    "        X_valid, y_valid = train_feats.iloc[valid_idx][train_cols], train_feats.iloc[valid_idx][target_col]\n",
    "\n",
    "        valid_predict = lgb_calc_OOF(X_train, y_train, X_valid, y_valid, i, j, RANDOM_STATE=41 + i, save=True)\n",
    "\n",
    "        OOF_SCORE[valid_idx] += valid_predict / iterations\n",
    "        j+=1\n",
    "        # models_dict[f'{fold}_{i}'] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('OOF metric LGBM = {:.5f}'.format(metrics.mean_squared_error(train_feats[target_col], \n",
    "                                                                   OOF_SCORE,\n",
    "                                                                   squared=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('base_lgb/OOF_base_lgb.pkl', 'wb') as f:\n",
    "    pickle.dump(OOF_SCORE, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.scatter(OOF_SCORE, train_feats['score'])\n",
    "add_identity(ax, color='r', ls='--')\n",
    "# ax.scatter(stds, train_scores_df['score']-means)\n",
    "plt.ylabel('True Values')\n",
    "plt.xlabel('Predictions')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
