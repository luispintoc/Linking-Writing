{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shap\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, r2_score, mean_absolute_error, mean_squared_error\n",
    "import ast\n",
    "import numpy as np\n",
    "import random, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "SEED = 1234\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../feature_eng/example_features.csv')\n",
    "df = df.drop(['Unnamed: 0', 'id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['score'], axis=1), df['score'], test_size=0.10, stratify=df['score'], random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shap_values(model, x_train):\n",
    "\n",
    "    assert type(x_train)==pd.core.frame.DataFrame\n",
    "\n",
    "    shap_explainer = shap.TreeExplainer(model)\n",
    "    shaps = pd.DataFrame(\n",
    "        data=shap_explainer.shap_values(x_train),\n",
    "        index=x_train.index,\n",
    "        columns=x_train.columns\n",
    "    )\n",
    "\n",
    "    return shaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_contributions(y_true, y_pred, shap_values):\n",
    "  \"\"\"Compute prediction contribution and error contribution for each feature.\"\"\"\n",
    "\n",
    "  prediction_contribution = shap_values.abs().mean().rename(\"prediction_contribution\")\n",
    "\n",
    "  abs_error = (y_true - y_pred).abs()\n",
    "  y_pred_wo_feature = shap_values.apply(lambda feature: y_pred - feature)\n",
    "  abs_error_wo_feature = y_pred_wo_feature.apply(lambda feature: (y_true - feature).abs())\n",
    "  error_contribution = abs_error_wo_feature.apply(lambda feature: abs_error - feature).mean().rename(\"error_contribution\")\n",
    "\n",
    "  return prediction_contribution, error_contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=SEED, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_error_list = []\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(skf.split(X_train, LabelEncoder().fit_transform(y_train))):\n",
    "    x_train_fold, x_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "    # prediction_contribution_train, error_contribution_train = get_feature_contributions(y_train_fold, y_train_pred, shap_values_train)\n",
    "    # prediction_contribution_val, error_contribution_val = get_feature_contributions(y_val_fold, y_val_pred, shap_values_val)\n",
    "\n",
    "    # contributions_train = pd.concat([prediction_contribution_train, error_contribution_train], axis=1)\n",
    "    # contributions_val = pd.concat([prediction_contribution_val, error_contribution_val], axis=1)\n",
    "\n",
    "    rfe_error = pd.DataFrame(dtype=float)\n",
    "    features_curr = list(x_train_fold.columns.copy())\n",
    "    feature_drop = None\n",
    "\n",
    "    for iteration in range(len(x_train_fold.columns)):\n",
    "\n",
    "        model = RandomForestRegressor(n_estimators=50)\n",
    "        model.fit(x_train_fold[features_curr], y_train_fold)\n",
    "        y_train_pred = model.predict(x_train_fold[features_curr])\n",
    "        y_val_pred = model.predict(x_val_fold[features_curr])\n",
    "        y_test_pred = model.predict(X_test[features_curr])\n",
    "\n",
    "        shap_values_train = get_shap_values(model, x_train_fold[features_curr])\n",
    "        shap_values_val = get_shap_values(model, x_val_fold[features_curr])\n",
    "    \n",
    "        prediction_contribution_val, error_contribution_val = get_feature_contributions(\n",
    "            y_true=y_val_fold, \n",
    "            y_pred=y_val_pred, \n",
    "            shap_values=shap_values_val\n",
    "        )\n",
    "\n",
    "        rfe_error.loc[iteration, \"feats\"] = str(list(features_curr))\n",
    "        rfe_error.loc[iteration, \"n_features\"] = len(features_curr)\n",
    "        rfe_error.loc[iteration, \"y_pred_test\"] = str(list(y_test_pred))\n",
    "        rfe_error.loc[iteration, \"contrib\"] = error_contribution_val.max()\n",
    "        rfe_error.loc[iteration, \"mae_trn\"] = mean_absolute_error(y_train_fold, y_train_pred)\n",
    "        rfe_error.loc[iteration, \"mae_val\"] = mean_absolute_error(y_val_fold, y_val_pred)\n",
    "        rfe_error.loc[iteration, \"mae_tst\"] = mean_absolute_error(y_test, y_test_pred)\n",
    "        rfe_error.loc[iteration, \"rmse_trn\"] = mean_squared_error(y_train_fold, y_train_pred, squared=False)\n",
    "        rfe_error.loc[iteration, \"rmse_val\"] = mean_squared_error(y_val_fold, y_val_pred, squared=False)\n",
    "        rfe_error.loc[iteration, \"rmse_tst\"] = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "        \n",
    "        feature_drop = error_contribution_val.idxmax()\n",
    "        features_curr.remove(feature_drop)\n",
    "    \n",
    "    rfe_error_list.append(rfe_error)\n",
    "    rfe_error.to_csv(f'./output/rfe_error_{i}_fold.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7046776316274904\n",
      "0.7124659018439568\n",
      "0.702010074828909\n",
      "0.7034064580036854\n",
      "0.7129742338012758\n"
     ]
    }
   ],
   "source": [
    "for error_df in rfe_error_list:\n",
    "    print(error_df.loc[error_df['rmse_val'].idxmin()]['rmse_tst'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for error_df in rfe_error_list:\n",
    "    preds.append(ast.literal_eval(error_df.loc[error_df['rmse_val'].idxmin()]['y_pred_test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5263467741935484\n",
      "0.6943468153595866\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(y_test, np.mean(preds, axis=0)))\n",
    "print(mean_squared_error(y_test, np.mean(preds, axis=0), squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
